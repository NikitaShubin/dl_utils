# Модуль `copybal.py`

## Общее описание
Модуль реализует алгоритм копирующей балансировки датасета для задач компьютерного зрения. Основная цель - выравнивание распределения классов объектов в датасете путем контролируемого дублирования изображений с сохранением контекста.

## Основные компоненты

### 1. Вспомогательные функции
#### Идентификация объектов:
- `build_unigue_track_id()` - создание уникального идентификатора объекта:
  - Объединяет информацию о файле, задаче, подзадаче, треке и метке
  - Использует специальный разделитель (sep_char)

- `split_unigue_track_id()` - обратная операция разбора идентификатора

#### Работа с графами связностей:
- `init_object_file_graph_by_task()` - инициализация графа для одной задачи:
  - Создает структуру для хранения связей объектов и файлов
  - Учитывает только используемые классы (labels_convertor(label) >= 0)

- `init_task_object_file_graphs()` - массовая инициализация графов для всех задач
- `update_object_file_graphs()` - обновление графов новыми связями
- `drop_unused_track_ids_in_graphs()` - очистка графов от неиспользуемых объектов

### 2. Основная функция балансировки
#### `make_copy_bal()`:
- Координирует весь процесс балансировки
- Выполняет:
  1. Подготовку путей и структур данных
  2. Парсинг графов связностей
  3. Оптимизацию числа копий через `torch_copy_bal`
  4. Создание дубликатов файлов

#### `torch_copy_bal()`:
- Реализует итеративный процесс оптимизации с использованием PyTorch
- Учитывает 4 компонента функции потерь:
  1. `files_counter_loss` - дисперсия числа копий файлов
  2. `object_loss` - дисперсия появления объектов
  3. `class_loss` - дисперсия распределения классов
  4. `superclass_loss` - дисперсия распределения суперклассов

### 3. Особенности реализации
1. **Сохранение контекста**:
   - Дублируются целые изображения
   - Используются жесткие ссылки для экономии места
   - Минимизируется потеря объектов при аугментации

2. **Многоуровневая балансировка**:
   - Учет отдельных объектов
   - Баланс внутри классов
   - Баланс между суперклассами
   - Контроль общего числа копий

3. **Оптимизация**:
   - Градиентный спуск с адаптивным learning rate
   - Ограничения на максимальное число копий
   - Контроль общего размера датасета

4. **Мониторинг**:
   - Сохранение истории оптимизации
   - Статистика на каждом шаге
   - Обработка прерываний

## Ключевые характеристики

### Входные данные:
- Графы связностей объектов (object_file_graphs)
- Директория с изображениями (img_dir)
- Параметры балансировки:
  - Максимальное число итераций (steps)
  - Лимит копий на файл (max_file_copy_num)
  - Максимальное увеличение датасета (max_ds_increase_frac)

### Выходные данные:
- Сбалансированный датасет (дубликаты файлов)
- История оптимизации (CSV-файл)
- Статистика процесса

### Ограничения:
- Требует GPU для эффективной работы
- Жесткие ссылки работают только в пределах одной ФС
- Сохранение исходного распределения объектов в кадре

## Алгоритм работы
1. Инициализация структур данных
2. Построение графов связности
3. Итеративная оптимизация:
   - Расчет функции потерь
   - Обновление счетчиков копий
   - Контроль ограничений
4. Создание дубликатов файлов
5. Сохранение результатов
